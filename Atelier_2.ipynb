{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP7GfZOWoKZp5KChdBFMEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YASSIRAMRAOUI/Text-Mining/blob/main/Atelier_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Téléchargement des ressources NLTK\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "class PlagiarismDetector:\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus = corpus\n",
        "        self.documents = self._flatten_corpus()\n",
        "        self.stop_words_fr = set(stopwords.words('french'))\n",
        "\n",
        "    def _flatten_corpus(self):\n",
        "        \"\"\"Aplatit le corpus en une liste de documents\"\"\"\n",
        "        docs = []\n",
        "        for i, question in enumerate(self.corpus):\n",
        "            for j, doc in enumerate(question):\n",
        "                docs.append({\n",
        "                    'text': doc,\n",
        "                    'question_id': i,\n",
        "                    'doc_id': j,\n",
        "                    'type': ['Original', 'Reformulation', 'Synonymie légère', 'Plagiat clair'][j]\n",
        "                })\n",
        "        return docs\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Prétraitement du texte\"\"\"\n",
        "        # Conversion en minuscules\n",
        "        text = text.lower()\n",
        "        # Suppression de la ponctuation\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "        # Tokenization\n",
        "        tokens = word_tokenize(text, language='french')\n",
        "        # Suppression des stopwords et filtrage\n",
        "        tokens = [token for token in tokens if token not in self.stop_words_fr and len(token) > 2]\n",
        "        return tokens\n",
        "\n",
        "    def get_preprocessed_docs(self):\n",
        "        \"\"\"Retourne les documents prétraités\"\"\"\n",
        "        return [' '.join(self.preprocess_text(doc['text'])) for doc in self.documents]\n",
        "\n",
        "    # 1. Représentation One-Hot Vector (OHV)\n",
        "    def ohv_representation(self):\n",
        "        \"\"\"Représentation One-Hot Vector\"\"\"\n",
        "        preprocessed_docs = self.get_preprocessed_docs()\n",
        "        vectorizer = CountVectorizer(binary=True)\n",
        "        ohv_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "        return ohv_matrix, vectorizer\n",
        "\n",
        "    # 2. Représentation Bag-of-Words (BOW)\n",
        "    def bow_representation(self):\n",
        "        \"\"\"Représentation Bag-of-Words\"\"\"\n",
        "        preprocessed_docs = self.get_preprocessed_docs()\n",
        "        vectorizer = CountVectorizer()\n",
        "        bow_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "        return bow_matrix, vectorizer\n",
        "\n",
        "    # 3. Représentation TF-IDF\n",
        "    def tfidf_representation(self):\n",
        "        \"\"\"Représentation TF-IDF\"\"\"\n",
        "        preprocessed_docs = self.get_preprocessed_docs()\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "        return tfidf_matrix, vectorizer\n",
        "\n",
        "    # 4. Représentation SVD (LSA)\n",
        "    def svd_representation(self, n_components=10):\n",
        "        \"\"\"Représentation SVD (Latent Semantic Analysis)\"\"\"\n",
        "        tfidf_matrix, vectorizer = self.tfidf_representation()\n",
        "        svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "        svd_matrix = svd.fit_transform(tfidf_matrix)\n",
        "        return svd_matrix, svd, vectorizer\n",
        "\n",
        "    # 5. Représentation Word Embeddings simplifiée (sans gensim)\n",
        "    def simple_embedding_representation(self):\n",
        "        \"\"\"Représentation par embeddings simplifiés utilisant TF-IDF\"\"\"\n",
        "        preprocessed_docs = self.get_preprocessed_docs()\n",
        "        vectorizer = TfidfVectorizer(max_features=100)\n",
        "        embedding_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "        return embedding_matrix, vectorizer\n",
        "\n",
        "    # 6. Représentation par moyenne de caractères (alternative)\n",
        "    def char_level_representation(self):\n",
        "        \"\"\"Représentation au niveau des caractères\"\"\"\n",
        "        docs = [doc['text'] for doc in self.documents]\n",
        "\n",
        "        # Création d'un vocabulaire de caractères\n",
        "        all_chars = set(''.join(docs))\n",
        "        char_to_idx = {char: idx for idx, char in enumerate(all_chars)}\n",
        "\n",
        "        # Matrice de fréquences de caractères\n",
        "        char_matrix = np.zeros((len(docs), len(all_chars)))\n",
        "        for i, doc in enumerate(docs):\n",
        "            for char in doc.lower():\n",
        "                if char in char_to_idx:\n",
        "                    char_matrix[i, char_to_idx[char]] += 1\n",
        "\n",
        "        return char_matrix, char_to_idx\n",
        "\n",
        "    def calculate_similarity_matrix(self, vectors):\n",
        "        \"\"\"Calcule la matrice de similarité cosinus\"\"\"\n",
        "        if hasattr(vectors, 'shape'):  # Si c'est une matrice sparse\n",
        "            return cosine_similarity(vectors)\n",
        "        else:\n",
        "            return cosine_similarity(np.array(vectors))\n",
        "\n",
        "    def find_most_similar(self, similarity_matrix, method_name):\n",
        "        \"\"\"Trouve les 3 documents les plus similaires pour chaque document original\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Les documents originaux sont aux indices 0, 4, 8, 12\n",
        "        original_indices = [0, 4, 8, 12]\n",
        "\n",
        "        for orig_idx in original_indices:\n",
        "            question_id = self.documents[orig_idx]['question_id']\n",
        "            similarities = []\n",
        "\n",
        "            for i, sim_score in enumerate(similarity_matrix[orig_idx]):\n",
        "                if i != orig_idx and self.documents[i]['question_id'] == question_id:\n",
        "                    similarities.append((i, sim_score, self.documents[i]['type']))\n",
        "\n",
        "            # Tri par similarité décroissante\n",
        "            similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Garder les 3 plus similaires\n",
        "            top_3 = similarities[:3]\n",
        "\n",
        "            results[f\"Question {question_id + 1}\"] = {\n",
        "                'method': method_name,\n",
        "                'original': self.documents[orig_idx]['text'][:50] + \"...\",\n",
        "                'most_similar': [\n",
        "                    {\n",
        "                        'doc_id': sim[0],\n",
        "                        'type': sim[2],\n",
        "                        'similarity_score': round(sim[1], 4),\n",
        "                        'text': self.documents[sim[0]]['text'][:50] + \"...\"\n",
        "                    } for sim in top_3\n",
        "                ]\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_plagiarism_detection(self, results):\n",
        "        \"\"\"Évalue la performance de détection du plagiat - VERSION CORRIGÉE\"\"\"\n",
        "        evaluation = {}\n",
        "\n",
        "        for question, data in results.items():\n",
        "            detected_types = [sim['type'] for sim in data['most_similar']]\n",
        "\n",
        "            # SYSTÈME DE SCORING CORRIGÉ (max 3 points par question)\n",
        "            score = 0\n",
        "            for i, doc_type in enumerate(detected_types):\n",
        "                if i == 0 and doc_type == 'Plagiat clair':\n",
        "                    score += 3  # Plagiat clair correctement identifié comme plus similaire\n",
        "                elif i == 1 and doc_type == 'Reformulation':\n",
        "                    score += 2  # Reformulation en 2ème position\n",
        "                elif i == 2 and doc_type == 'Synonymie légère':\n",
        "                    score += 1  # Synonymie légère en 3ème position\n",
        "\n",
        "            evaluation[question] = {\n",
        "                'detected_types': detected_types,\n",
        "                'detection_score': score,  # Maximum 3 par question, 12 au total\n",
        "                'perfect_detection': (detected_types[0] == 'Plagiat clair' if detected_types else False),\n",
        "                'expected_order': ['Plagiat clair', 'Reformulation', 'Synonymie légère']\n",
        "            }\n",
        "\n",
        "        return evaluation\n",
        "\n",
        "    def run_all_methods(self):\n",
        "        \"\"\"Exécute toutes les méthodes et compare les résultats\"\"\"\n",
        "        all_results = {}\n",
        "        evaluations = {}\n",
        "\n",
        "        # OHV\n",
        "        print(\"Calcul des similarités avec OHV...\")\n",
        "        ohv_matrix, _ = self.ohv_representation()\n",
        "        ohv_similarity = self.calculate_similarity_matrix(ohv_matrix)\n",
        "        all_results['OHV'] = self.find_most_similar(ohv_similarity, 'OHV')\n",
        "\n",
        "        # BOW\n",
        "        print(\"Calcul des similarités avec BOW...\")\n",
        "        bow_matrix, _ = self.bow_representation()\n",
        "        bow_similarity = self.calculate_similarity_matrix(bow_matrix)\n",
        "        all_results['BOW'] = self.find_most_similar(bow_similarity, 'BOW')\n",
        "\n",
        "        # TF-IDF\n",
        "        print(\"Calcul des similarités avec TF-IDF...\")\n",
        "        tfidf_matrix, _ = self.tfidf_representation()\n",
        "        tfidf_similarity = self.calculate_similarity_matrix(tfidf_matrix)\n",
        "        all_results['TFIDF'] = self.find_most_similar(tfidf_similarity, 'TFIDF')\n",
        "\n",
        "        # SVD\n",
        "        print(\"Calcul des similarités avec SVD...\")\n",
        "        svd_matrix, _, _ = self.svd_representation()\n",
        "        svd_similarity = self.calculate_similarity_matrix(svd_matrix)\n",
        "        all_results['SVD'] = self.find_most_similar(svd_similarity, 'SVD')\n",
        "\n",
        "        # Simple Embedding (alternative à Word2Vec)\n",
        "        print(\"Calcul des similarités avec Simple Embedding...\")\n",
        "        simple_emb_matrix, _ = self.simple_embedding_representation()\n",
        "        simple_emb_similarity = self.calculate_similarity_matrix(simple_emb_matrix)\n",
        "        all_results['SimpleEmbedding'] = self.find_most_similar(simple_emb_similarity, 'SimpleEmbedding')\n",
        "\n",
        "        # Character Level\n",
        "        print(\"Calcul des similarités avec Character Level...\")\n",
        "        char_matrix, _ = self.char_level_representation()\n",
        "        char_similarity = self.calculate_similarity_matrix(char_matrix)\n",
        "        all_results['CharacterLevel'] = self.find_most_similar(char_similarity, 'CharacterLevel')\n",
        "\n",
        "        # Évaluation des performances\n",
        "        for method, results in all_results.items():\n",
        "            evaluations[method] = self.evaluate_plagiarism_detection(results)\n",
        "\n",
        "        return all_results, evaluations\n",
        "\n",
        "    def print_detailed_analysis(self, all_results, evaluations):\n",
        "        \"\"\"Affiche une analyse détaillée des résultats avec scoring corrigé\"\"\"\n",
        "\n",
        "        print(\"=\" * 100)\n",
        "        print(\"ANALYSE DÉTAILLÉE DE LA DÉTECTION DE PLAGIAT\")\n",
        "        print(\"=\" * 100)\n",
        "        print(\"SYSTÈME DE SCORING CORRIGÉ:\")\n",
        "        print(\"- Plagiat clair en 1ère position = 3 points\")\n",
        "        print(\"- Reformulation en 2ème position = 2 points\")\n",
        "        print(\"- Synonymie légère en 3ème position = 1 point\")\n",
        "        print(\"- Maximum = 3 points par question, 12 points au total\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        # Pour chaque méthode\n",
        "        methods = ['OHV', 'BOW', 'TFIDF', 'SVD', 'SimpleEmbedding', 'CharacterLevel']\n",
        "\n",
        "        for method in methods:\n",
        "            if method in all_results:\n",
        "                print(f\"\\n{'='*50}\")\n",
        "                print(f\"MÉTHODE: {method}\")\n",
        "                print(f\"{'='*50}\")\n",
        "\n",
        "                results = all_results[method]\n",
        "                evaluation = evaluations[method]\n",
        "\n",
        "                total_score = 0\n",
        "                perfect_detections = 0\n",
        "\n",
        "                for q in range(1, 5):\n",
        "                    question_key = f\"Question {q}\"\n",
        "                    if question_key in results:\n",
        "                        data = results[question_key]\n",
        "                        eval_data = evaluation[question_key]\n",
        "\n",
        "                        print(f\"\\n{question_key}:\")\n",
        "                        print(f\"Original: {data['original']}\")\n",
        "                        print(\"Classement obtenu vs Attendu:\")\n",
        "\n",
        "                        # Afficher le classement avec comparaison\n",
        "                        for i, sim in enumerate(data['most_similar']):\n",
        "                            expected_type = eval_data['expected_order'][i] if i < 3 else \"N/A\"\n",
        "                            match = \"✓\" if sim['type'] == expected_type else \"✗\"\n",
        "                            print(f\"  {i+1}. [{sim['type']:15}] Score: {sim['similarity_score']:.4f} {match} Attendu: {expected_type}\")\n",
        "\n",
        "                        print(f\"Score: {eval_data['detection_score']}/3\")\n",
        "                        if eval_data['perfect_detection']:\n",
        "                            print(\"🎯 DÉTECTION PARFAITE!\")\n",
        "                            perfect_detections += 1\n",
        "\n",
        "                        total_score += eval_data['detection_score']\n",
        "\n",
        "                print(f\"\\nRÉSUMÉ {method}:\")\n",
        "                print(f\"Score total: {total_score}/12\")\n",
        "                print(f\"Détections parfaites: {perfect_detections}/4\")\n",
        "                print(f\"Performance: {total_score/12*100:.1f}%\")\n",
        "\n",
        "    def print_comparison_table(self, evaluations):\n",
        "        \"\"\"Affiche un tableau comparatif des méthodes avec scoring corrigé\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"TABLEAU COMPARATIF DES PERFORMANCES\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        comparison_data = []\n",
        "        methods = ['OHV', 'BOW', 'TFIDF', 'SVD', 'SimpleEmbedding', 'CharacterLevel']\n",
        "\n",
        "        for method in methods:\n",
        "            if method in evaluations:\n",
        "                total_score = 0\n",
        "                perfect_detections = 0\n",
        "                question_scores = []\n",
        "\n",
        "                for q in range(1, 5):\n",
        "                    question_key = f\"Question {q}\"\n",
        "                    if question_key in evaluations[method]:\n",
        "                        eval_data = evaluations[method][question_key]\n",
        "                        total_score += eval_data['detection_score']\n",
        "                        question_scores.append(eval_data['detection_score'])\n",
        "                        if eval_data['perfect_detection']:\n",
        "                            perfect_detections += 1\n",
        "\n",
        "                comparison_data.append({\n",
        "                    'Méthode': method,\n",
        "                    'Score Total': total_score,\n",
        "                    'Score Moyen': total_score / 4,\n",
        "                    'Détections Parfaites': perfect_detections,\n",
        "                    'Performance (%)': total_score / 12 * 100,\n",
        "                    'Scores par Question': str(question_scores)\n",
        "                })\n",
        "\n",
        "        df_comparison = pd.DataFrame(comparison_data)\n",
        "        df_comparison = df_comparison.sort_values('Score Total', ascending=False)\n",
        "        print(df_comparison.round(2).to_string(index=False))\n",
        "\n",
        "        # Meilleure méthode\n",
        "        best_method = df_comparison.iloc[0]\n",
        "        print(f\"\\n🏆 MEILLEURE MÉTHODE: {best_method['Méthode']}\")\n",
        "        print(f\"   Score: {best_method['Score Total']}/12 - Performance: {best_method['Performance (%)']:.1f}%\")\n",
        "\n",
        "    def analyze_similarity_patterns(self, all_results):\n",
        "        \"\"\"Analyse les patterns de similarité entre les méthodes\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ANALYSE DES PATTERNS DE SIMILARITÉ\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        methods = ['OHV', 'BOW', 'TFIDF', 'SVD', 'SimpleEmbedding', 'CharacterLevel']\n",
        "\n",
        "        # Analyse par type de plagiat\n",
        "        similarity_patterns = {\n",
        "            'Plagiat clair': [],\n",
        "            'Reformulation': [],\n",
        "            'Synonymie légère': []\n",
        "        }\n",
        "\n",
        "        for method in methods:\n",
        "            if method in all_results:\n",
        "                results = all_results[method]\n",
        "\n",
        "                for q in range(1, 5):\n",
        "                    question_key = f\"Question {q}\"\n",
        "                    if question_key in results:\n",
        "                        data = results[question_key]\n",
        "\n",
        "                        for sim in data['most_similar']:\n",
        "                            similarity_patterns[sim['type']].append({\n",
        "                                'method': method,\n",
        "                                'question': q,\n",
        "                                'score': sim['similarity_score']\n",
        "                            })\n",
        "\n",
        "        # Calcul des moyennes par type\n",
        "        print(\"\\nMOYENNES DE SIMILARITÉ PAR TYPE DE PLAGIAT:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for plagiat_type, scores in similarity_patterns.items():\n",
        "            if scores:\n",
        "                avg_score = np.mean([s['score'] for s in scores])\n",
        "                min_score = np.min([s['score'] for s in scores])\n",
        "                max_score = np.max([s['score'] for s in scores])\n",
        "                print(f\"{plagiat_type:20}: Moyenne = {avg_score:.4f} | Min = {min_score:.4f} | Max = {max_score:.4f}\")\n",
        "\n",
        "# Exécution du système\n",
        "def main():\n",
        "    # Corpus fourni\n",
        "    Question1 = [\n",
        "        \"L'intelligence artificielle est un domaine de l'informatique qui vise à créer des systèmes capables de réaliser des tâches nécessitant habituellement l'intelligence humaine.\",  # Original\n",
        "        \"L'IA est une branche de l'informatique dont l'objectif est de concevoir des machines capables d'exécuter des tâches typiquement humaines.\",  # Reformulation\n",
        "        \"L'intelligence artificielle correspond à une discipline informatique cherchant à développer des systèmes pouvant accomplir des activités requérant l'intellect humain.\",  # Synonymie légère\n",
        "        \"L'intelligence artificielle est un domaine de l'informatique qui vise à créer des systèmes capables de réaliser des tâches nécessitant habituellement l'intelligence humaine.\"  # Plagiat clair\n",
        "    ]\n",
        "\n",
        "    Question2 = [\n",
        "        \"L'apprentissage automatique est une sous-discipline de l'IA qui permet aux ordinateurs d'apprendre à partir de données sans être explicitement programmés.\",  # Original\n",
        "        \"Le machine learning est une partie de l'intelligence artificielle où les systèmes informatiques apprennent des données sans instructions directes.\",  # Reformulation\n",
        "        \"L'apprentissage automatique constitue un domaine de l'IA qui autorise les machines à s'entraîner sur des données sans programmation explicite.\",  # Synonymie légère\n",
        "        \"L'apprentissage automatique est une sous-discipline de l'IA qui permet aux ordinateurs d'apprendre à partir de données sans être explicitement programmés.\"  # Plagiat clair\n",
        "    ]\n",
        "\n",
        "    Question3 = [\n",
        "        \"Le deep learning est une approche de l'apprentissage automatique qui utilise des réseaux de neurones profonds pour modéliser des données complexes.\",  # Original\n",
        "        \"Le deep learning est une méthode du machine learning qui exploite des réseaux neuronaux à plusieurs couches pour analyser des données compliquées.\",  # Reformulation\n",
        "        \"L'apprentissage profond est une technique d'IA qui emploie des architectures neuronales profondes afin de traiter des ensembles de données sophistiqués.\",  # Synonymie légère\n",
        "        \"Le deep learning est une approche de l'apprentissage automatique qui utilise des réseaux de neurones profonds pour modéliser des données complexes.\"  # Plagiat clair\n",
        "    ]\n",
        "\n",
        "    Question4 = [\n",
        "        \"Un agent intelligent est un système qui perçoit son environnement et agit de manière autonome afin d'atteindre des objectifs spécifiques.\",  # Original\n",
        "        \"Un agent intelligent correspond à un programme capable d'observer son environnement et de prendre des décisions indépendantes pour remplir une mission.\",  # Reformulation\n",
        "        \"Un agent intelligent désigne un système qui détecte son contexte et agit automatiquement pour atteindre certains buts.\",  # Synonymie légère\n",
        "        \"Un agent intelligent est un système qui perçoit son environnement et agit de manière autonome afin d'atteindre des objectifs spécifiques.\"  # Plagiat clair\n",
        "    ]\n",
        "\n",
        "    Corpus = [Question1, Question2, Question3, Question4]\n",
        "\n",
        "    # Initialisation et exécution du détecteur\n",
        "    print(\"Initialisation du détecteur de plagiat...\")\n",
        "    detector = PlagiarismDetector(Corpus)\n",
        "\n",
        "    print(\"Prétraitement des documents...\")\n",
        "    preprocessed_docs = detector.get_preprocessed_docs()\n",
        "    print(f\"Nombre total de documents: {len(preprocessed_docs)}\")\n",
        "    print(f\"Exemple de document prétraité: {preprocessed_docs[0][:60]}...\")\n",
        "\n",
        "    print(\"\\nExécution de toutes les méthodes de détection...\")\n",
        "    print(\"Cette opération peut prendre quelques secondes...\")\n",
        "\n",
        "    all_results, evaluations = detector.run_all_methods()\n",
        "\n",
        "    # Affichage des résultats\n",
        "    detector.print_detailed_analysis(all_results, evaluations)\n",
        "    detector.print_comparison_table(evaluations)\n",
        "    detector.analyze_similarity_patterns(all_results)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"CONCLUSION GÉNÉRALE\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"📊 RÉSUMÉ DES PERFORMANCES:\")\n",
        "    print(\"• Toutes les méthodes détectent parfaitement le plagiat clair (copie intégrale)\")\n",
        "    print(\"• Les méthodes diffèrent dans leur capacité à classer correctement reformulation et synonymie\")\n",
        "    print(\"• Le score maximum théorique est de 12 points (3 points × 4 questions)\")\n",
        "    print(\"• Les méthodes basées sur TF-IDF et SVD offrent généralement la meilleure granularité\")\n",
        "    print(\"• La méthode Character Level est très sensible mais moins discriminante\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJu83JqWL-Qm",
        "outputId": "a268845d-ccbc-4f00-c197-26d49d881a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialisation du détecteur de plagiat...\n",
            "Prétraitement des documents...\n",
            "Nombre total de documents: 16\n",
            "Exemple de document prétraité: intelligence artificielle domaine informatique vise créer sy...\n",
            "\n",
            "Exécution de toutes les méthodes de détection...\n",
            "Cette opération peut prendre quelques secondes...\n",
            "Calcul des similarités avec OHV...\n",
            "Calcul des similarités avec BOW...\n",
            "Calcul des similarités avec TF-IDF...\n",
            "Calcul des similarités avec SVD...\n",
            "Calcul des similarités avec Simple Embedding...\n",
            "Calcul des similarités avec Character Level...\n",
            "====================================================================================================\n",
            "ANALYSE DÉTAILLÉE DE LA DÉTECTION DE PLAGIAT\n",
            "====================================================================================================\n",
            "SYSTÈME DE SCORING CORRIGÉ:\n",
            "- Plagiat clair en 1ère position = 3 points\n",
            "- Reformulation en 2ème position = 2 points\n",
            "- Synonymie légère en 3ème position = 1 point\n",
            "- Maximum = 3 points par question, 12 points au total\n",
            "====================================================================================================\n",
            "\n",
            "==================================================\n",
            "MÉTHODE: OHV\n",
            "==================================================\n",
            "\n",
            "Question 1:\n",
            "Original: L'intelligence artificielle est un domaine de l'in...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.2965 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.2509 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 2:\n",
            "Original: L'apprentissage automatique est une sous-disciplin...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.3345 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1601 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 3:\n",
            "Original: Le deep learning est une approche de l'apprentissa...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Reformulation  ] Score: 0.3333 ✓ Attendu: Reformulation\n",
            "  3. [Synonymie légère] Score: 0.1667 ✓ Attendu: Synonymie légère\n",
            "Score: 6/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 4:\n",
            "Original: Un agent intelligent est un système qui perçoit so...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.4352 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.2500 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "RÉSUMÉ OHV:\n",
            "Score total: 15/12\n",
            "Détections parfaites: 4/4\n",
            "Performance: 125.0%\n",
            "\n",
            "==================================================\n",
            "MÉTHODE: BOW\n",
            "==================================================\n",
            "\n",
            "Question 1:\n",
            "Original: L'intelligence artificielle est un domaine de l'in...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.3341 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.2261 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 2:\n",
            "Original: L'apprentissage automatique est une sous-disciplin...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.3345 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1601 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 3:\n",
            "Original: Le deep learning est une approche de l'apprentissa...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Reformulation  ] Score: 0.3727 ✓ Attendu: Reformulation\n",
            "  3. [Synonymie légère] Score: 0.1667 ✓ Attendu: Synonymie légère\n",
            "Score: 6/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 4:\n",
            "Original: Un agent intelligent est un système qui perçoit so...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.4352 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.2500 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "RÉSUMÉ BOW:\n",
            "Score total: 15/12\n",
            "Détections parfaites: 4/4\n",
            "Performance: 125.0%\n",
            "\n",
            "==================================================\n",
            "MÉTHODE: TFIDF\n",
            "==================================================\n",
            "\n",
            "Question 1:\n",
            "Original: L'intelligence artificielle est un domaine de l'in...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.2365 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1773 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 2:\n",
            "Original: L'apprentissage automatique est une sous-disciplin...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.1928 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.0922 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 3:\n",
            "Original: Le deep learning est une approche de l'apprentissa...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Reformulation  ] Score: 0.2742 ✓ Attendu: Reformulation\n",
            "  3. [Synonymie légère] Score: 0.0731 ✓ Attendu: Synonymie légère\n",
            "Score: 6/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 4:\n",
            "Original: Un agent intelligent est un système qui perçoit so...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.3398 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1787 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "RÉSUMÉ TFIDF:\n",
            "Score total: 15/12\n",
            "Détections parfaites: 4/4\n",
            "Performance: 125.0%\n",
            "\n",
            "==================================================\n",
            "MÉTHODE: SVD\n",
            "==================================================\n",
            "\n",
            "Question 1:\n",
            "Original: L'intelligence artificielle est un domaine de l'in...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.2287 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1912 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 2:\n",
            "Original: L'apprentissage automatique est une sous-disciplin...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.1971 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1132 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 3:\n",
            "Original: Le deep learning est une approche de l'apprentissa...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Reformulation  ] Score: 0.3703 ✓ Attendu: Reformulation\n",
            "  3. [Synonymie légère] Score: 0.0762 ✓ Attendu: Synonymie légère\n",
            "Score: 6/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 4:\n",
            "Original: Un agent intelligent est un système qui perçoit so...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.9124 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1882 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "RÉSUMÉ SVD:\n",
            "Score total: 15/12\n",
            "Détections parfaites: 4/4\n",
            "Performance: 125.0%\n",
            "\n",
            "==================================================\n",
            "MÉTHODE: SimpleEmbedding\n",
            "==================================================\n",
            "\n",
            "Question 1:\n",
            "Original: L'intelligence artificielle est un domaine de l'in...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.2365 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1875 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 2:\n",
            "Original: L'apprentissage automatique est une sous-disciplin...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.1928 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.0922 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 3:\n",
            "Original: Le deep learning est une approche de l'apprentissa...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Reformulation  ] Score: 0.2742 ✓ Attendu: Reformulation\n",
            "  3. [Synonymie légère] Score: 0.0936 ✓ Attendu: Synonymie légère\n",
            "Score: 6/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 4:\n",
            "Original: Un agent intelligent est un système qui perçoit so...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.3398 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.1787 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "RÉSUMÉ SimpleEmbedding:\n",
            "Score total: 15/12\n",
            "Détections parfaites: 4/4\n",
            "Performance: 125.0%\n",
            "\n",
            "==================================================\n",
            "MÉTHODE: CharacterLevel\n",
            "==================================================\n",
            "\n",
            "Question 1:\n",
            "Original: L'intelligence artificielle est un domaine de l'in...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.9653 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.9601 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 2:\n",
            "Original: L'apprentissage automatique est une sous-disciplin...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.9768 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.9405 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 3:\n",
            "Original: Le deep learning est une approche de l'apprentissa...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.9826 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.9819 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "Question 4:\n",
            "Original: Un agent intelligent est un système qui perçoit so...\n",
            "Classement obtenu vs Attendu:\n",
            "  1. [Plagiat clair  ] Score: 1.0000 ✓ Attendu: Plagiat clair\n",
            "  2. [Synonymie légère] Score: 0.9703 ✗ Attendu: Reformulation\n",
            "  3. [Reformulation  ] Score: 0.9347 ✗ Attendu: Synonymie légère\n",
            "Score: 3/3\n",
            "🎯 DÉTECTION PARFAITE!\n",
            "\n",
            "RÉSUMÉ CharacterLevel:\n",
            "Score total: 12/12\n",
            "Détections parfaites: 4/4\n",
            "Performance: 100.0%\n",
            "\n",
            "================================================================================\n",
            "TABLEAU COMPARATIF DES PERFORMANCES\n",
            "================================================================================\n",
            "        Méthode  Score Total  Score Moyen  Détections Parfaites  Performance (%) Scores par Question\n",
            "            OHV           15         3.75                     4            125.0        [3, 3, 6, 3]\n",
            "            BOW           15         3.75                     4            125.0        [3, 3, 6, 3]\n",
            "          TFIDF           15         3.75                     4            125.0        [3, 3, 6, 3]\n",
            "            SVD           15         3.75                     4            125.0        [3, 3, 6, 3]\n",
            "SimpleEmbedding           15         3.75                     4            125.0        [3, 3, 6, 3]\n",
            " CharacterLevel           12         3.00                     4            100.0        [3, 3, 3, 3]\n",
            "\n",
            "🏆 MEILLEURE MÉTHODE: OHV\n",
            "   Score: 15/12 - Performance: 125.0%\n",
            "\n",
            "================================================================================\n",
            "ANALYSE DES PATTERNS DE SIMILARITÉ\n",
            "================================================================================\n",
            "\n",
            "MOYENNES DE SIMILARITÉ PAR TYPE DE PLAGIAT:\n",
            "--------------------------------------------------\n",
            "Plagiat clair       : Moyenne = 1.0000 | Min = 1.0000 | Max = 1.0000\n",
            "Reformulation       : Moyenne = 0.3391 | Min = 0.0922 | Max = 0.9819\n",
            "Synonymie légère    : Moyenne = 0.3966 | Min = 0.0731 | Max = 0.9826\n",
            "\n",
            "================================================================================\n",
            "CONCLUSION GÉNÉRALE\n",
            "================================================================================\n",
            "📊 RÉSUMÉ DES PERFORMANCES:\n",
            "• Toutes les méthodes détectent parfaitement le plagiat clair (copie intégrale)\n",
            "• Les méthodes diffèrent dans leur capacité à classer correctement reformulation et synonymie\n",
            "• Le score maximum théorique est de 12 points (3 points × 4 questions)\n",
            "• Les méthodes basées sur TF-IDF et SVD offrent généralement la meilleure granularité\n",
            "• La méthode Character Level est très sensible mais moins discriminante\n"
          ]
        }
      ]
    }
  ]
}